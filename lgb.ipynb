{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nimport gc\nimport riiideducation\nenv = riiideducation.make_env()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dir_path = '/kaggle/input/riiid-test-answer-prediction/'\nfile_train = 'train.csv'\nfile_questions = 'questions.csv'\nfile_lectures = 'lectures.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# nrows = 100 * 10000\nnrows = None\n\n# 读数据的时候加上类型\ntrain = pd.read_csv(\n                    dir_path + file_train, \n                    nrows=nrows, \n                    usecols=['row_id', 'timestamp', 'user_id', 'content_id', \n                             'content_type_id', 'task_container_id', 'answered_correctly',\n                            'prior_question_elapsed_time','prior_question_had_explanation'],\n                    dtype={\n                            'row_id': 'int64',\n                            'timestamp': 'int64',\n                            'user_id': 'int32',\n                            'content_id': 'int16',\n                            'content_type_id': 'int8',\n                            'task_container_id': 'int8',\n                            'answered_correctly': 'int8',\n                            'prior_question_elapsed_time': 'float32',\n                            'prior_question_had_explanation': 'str'\n                        }\n                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lectures = pd.read_csv(\n                       dir_path + file_lectures, \n                       usecols=['lecture_id','tag','part','type_of'], \n                       nrows=nrows,\n                       dtype={\n                           'lecture_id': 'int16',\n                           'tag': 'int16',\n                           'part': 'int8',\n                           'type_of': 'str'\n                       }\n                    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions = pd.read_csv(\n                        dir_path + file_questions, \n                        nrows=nrows,\n                        usecols=['question_id','bundle_id','part','tags'], \n                        dtype={\n                           'question_id': 'int16',\n                           'bundle_id': 'int16',\n                           'part': 'int8',\n                           'tags': 'str'\n                       }\n                    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 数据处理\ntrain['prior_question_had_explanation'] = train['prior_question_had_explanation'].map({'True':1,'False':0}).fillna(-1).astype(np.int8)\nlectures['type_of'] = lectures['type_of'].map({'concept':0, 'intention':1, 'solving question':2, 'starter':3}).fillna(-1).astype(np.int8)\nquestions['tags'] = questions['tags'].map(lambda x:len(str(x).split(' ')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 压缩内存\nmax_num = 1000\ntrain = train.groupby(['user_id']).tail(max_num)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 切分数据\ntrain_lectures = train[train['content_type_id']==1]\ntrain_questions = train[train['content_type_id']==0]\ndel train\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 关联数据\ntrain_lectures_info = pd.merge(\n        left=train_lectures,\n        right=lectures,\n        how='left',\n        left_on='content_id',\n        right_on='lecture_id'\n        )\n\ntrain_questions_info = pd.merge(\n        left=train_questions,\n        right=questions,\n        how='left',\n        left_on='content_id',\n        right_on='question_id'\n        )\n\ndel train_lectures\ndel train_questions\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 提取特征函数\n# 文献课程类函数\ndef get_lecture_basic_features__user(train_lectures_info):\n    gb_columns = ['user_id']\n    gb_suffixes = 'lecture_'+'_'.join(gb_columns)\n    \n    agg_func = {\n        'lecture_id': [np.size],\n        'task_container_id': [lambda x: len(set(x))],\n        'tag': [lambda x: len(set(x))],\n\n        # part 展开\n        'part': [lambda x: len(set(x))],\n\n        # type_of 展开\n        'type_of': [lambda x: len(set(x))],\n    }\n    columns = [\n           gb_suffixes+'_size_lecture_id', \n           gb_suffixes+'_unique_task_container_id',\n           gb_suffixes+'_unique_tag',\n           gb_suffixes+'_unique_part',\n           gb_suffixes+'_unique_type_of'\n          ]  \n    train_lectures_info__user_f = train_lectures_info.\\\n                                groupby(gb_columns).\\\n                                agg(agg_func).\\\n                                reset_index()\n    \n    train_lectures_info__user_f.columns = gb_columns + columns\n    return train_lectures_info__user_f\n\ndef get_lecture_basic_features__user_tag(train_lectures_info):\n    gb_columns = ['user_id','tag']\n    gb_suffixes = 'lecture_'+'_'.join(gb_columns)\n    agg_func = {\n        'lecture_id': [np.size],\n        'task_container_id': [lambda x: len(set(x))],\n        'tag': [lambda x: len(set(x))],\n\n        # part 展开\n        'part': [lambda x: len(set(x))],\n    }\n    columns = [\n               gb_suffixes+'_size_lecture_id', \n               gb_suffixes+'_unique_task_container_id',\n               gb_suffixes+'_unique_tag',\n               gb_suffixes+'_unique_part'\n              ]    \n    train_lectures_info__user_tag_f = train_lectures_info.\\\n                                    groupby(gb_columns).\\\n                                    agg(agg_func).\\\n                                    reset_index()\n    train_lectures_info__user_tag_f.columns = gb_columns + columns    \n    return train_lectures_info__user_tag_f\n\n# 问答类函数\ndef get_questions_basic_features__user(train_questions_info):\n    gb_columns = ['user_id']\n    gb_suffixes = 'question_'+'_'.join(gb_columns)\n    agg_func = {\n        'answered_correctly': [np.mean,np.sum,np.std],\n\n        'question_id': [np.size],\n        'task_container_id': [lambda x: len(set(x))],\n\n        'prior_question_elapsed_time': [np.mean,np.max,np.min],\n\n        'prior_question_had_explanation': [lambda x: len(set(x))],\n\n        'bundle_id': [lambda x: len(set(x))],\n\n        # part 展开\n        'part': [lambda x: len(set(x))],\n        'tags': [lambda x: len(set(x))],\n    }\n    columns = [\n               gb_suffixes+'_answered_correctly_mean',\n               gb_suffixes+'_answered_correctly_max',\n               gb_suffixes+'_answered_correctly_min',\n\n               gb_suffixes+'_size_question_id', \n               gb_suffixes+'_unique_task_container_id',\n               gb_suffixes+'_prior_question_elapsed_time_mean',\n               gb_suffixes+'_prior_question_elapsed_time_max',\n               gb_suffixes+'_prior_question_elapsed_time_min',\n\n               gb_suffixes+'_unique_prior_question_had_explanation',\n\n               gb_suffixes+'_unique_bundle_id',\n               gb_suffixes+'_unique_part',\n               gb_suffixes+'_unique_tags',\n              ]\n    train_questions_info__user_f = train_questions_info.\\\n                                    groupby(gb_columns).\\\n                                    agg(agg_func).\\\n                                    reset_index()\n    train_questions_info__user_f.columns = gb_columns + columns    \n\n    return train_questions_info__user_f\n\ndef get_questions_basic_features__user_part(train_questions_info):\n    gb_columns = ['user_id','part']\n    gb_suffixes = 'question_'+'_'.join(gb_columns)\n    agg_func = {\n        'answered_correctly': [np.mean,np.sum,np.std],\n\n        'question_id': [np.size],\n        'task_container_id': [lambda x: len(set(x))],\n\n        'prior_question_elapsed_time': [np.mean,np.max,np.min],\n\n        'prior_question_had_explanation': [lambda x: len(set(x))],\n\n        'bundle_id': [lambda x: len(set(x))],\n\n        # part 展开\n        'part': [lambda x: len(set(x))],\n        'tags': [lambda x: len(set(x))],\n    }\n    columns = [\n               gb_suffixes+'_answered_correctly_mean',\n               gb_suffixes+'_answered_correctly_max',\n               gb_suffixes+'_answered_correctly_min',\n\n               gb_suffixes+'_size_question_id', \n               gb_suffixes+'_unique_task_container_id',\n               gb_suffixes+'_prior_question_elapsed_time_mean',\n               gb_suffixes+'_prior_question_elapsed_time_max',\n               gb_suffixes+'_prior_question_elapsed_time_min',\n\n               gb_suffixes+'_unique_prior_question_had_explanation',\n\n               gb_suffixes+'_unique_bundle_id',\n               gb_suffixes+'_unique_part',\n               gb_suffixes+'_unique_tags',\n              ]    \n    train_questions_info__user_part_f = train_questions_info.\\\n                                    groupby(gb_columns).\\\n                                    agg(agg_func).\\\n                                    reset_index()\n    train_questions_info__user_part_f.columns = gb_columns + columns    \n\n    return train_questions_info__user_part_f\n\ndef get_questions_basic_features__content(train_questions_info):\n    gb_columns = ['content_id']\n    gb_suffixes = 'question_'+'_'.join(gb_columns)\n    agg_func = {\n        'answered_correctly': [np.mean,np.sum,np.std],\n\n        'user_id': [np.size],\n\n        'prior_question_elapsed_time': [np.mean,np.max,np.min],\n\n        'prior_question_had_explanation': [lambda x: len(set(x))],\n    }\n    columns = [\n               gb_suffixes+'_answered_correctly_mean',\n               gb_suffixes+'_answered_correctly_max',\n               gb_suffixes+'_answered_correctly_min',\n\n               gb_suffixes+'_size_user_id', \n               gb_suffixes+'_prior_question_elapsed_time_mean',\n               gb_suffixes+'_prior_question_elapsed_time_max',\n               gb_suffixes+'_prior_question_elapsed_time_min',\n\n               gb_suffixes+'_unique_prior_question_had_explanation',\n              ]    \n    \n    train_questions_info__user_content_f = train_questions_info.\\\n                                    groupby(gb_columns).\\\n                                    agg(agg_func).\\\n                                    reset_index()\n    train_questions_info__user_content_f.columns = gb_columns + columns\n    \n    return train_questions_info__user_content_f","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 预测用户\ntest_lectures_info__user_f = get_lecture_basic_features__user(train_lectures_info)\n# test_lectures_info__user_tag_f = get_lecture_basic_features__user_tag(train_lectures_info)\ntest_questions_info__user_f = get_questions_basic_features__user(train_questions_info)\n# test_questions_info__user_part_f = get_questions_basic_features__user_part(train_questions_info)\ntest_questions_info__user_content_f = get_questions_basic_features__content(train_questions_info)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 验证数据\nvalid_data = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(3):\n    \n    # 获取训练标签数据\n    last_records = train_questions_info.drop_duplicates('user_id', keep='last')\n    \n    # 获取训练标签以前的数据\n    map__last_records__user_row = dict(zip(last_records['user_id'],last_records['row_id']))\n    \n    train_questions_info['filter_row'] = train_questions_info['user_id'].map(map__last_records__user_row)\n    train_lectures_info['filter_row'] = train_lectures_info['user_id'].map(map__last_records__user_row)\n\n    train_questions_info = train_questions_info[train_questions_info['row_id']<train_questions_info['filter_row']]\n    train_lectures_info = train_lectures_info[train_lectures_info['row_id']<train_lectures_info['filter_row']]\n    \n    # 获取特征\n    train_lectures_info__user_f = get_lecture_basic_features__user(train_lectures_info)\n    # train_lectures_info__user_tag_f = get_lecture_basic_features__user_tag(train_lectures_info)\n    train_questions_info__user_f = get_questions_basic_features__user(train_questions_info)\n    # train_questions_info__user_part_f = get_questions_basic_features__user_part(train_questions_info)\n    train_questions_info__user_content_f = get_questions_basic_features__content(train_questions_info)\n\n    last_records = last_records.merge(train_lectures_info__user_f,on=['user_id'],how='left')\n    last_records = last_records.merge(train_questions_info__user_f,on=['user_id'],how='left')\n    last_records = last_records.merge(train_questions_info__user_content_f,on=['content_id'],how='left')\n    \n    # 特征加入训练集\n    valid_data = valid_data.append(last_records)\n    print(len(valid_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 训练数据\ntrain_data = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(10):\n    \n    # 获取训练标签数据\n    last_records = train_questions_info.drop_duplicates('user_id', keep='last')\n    \n    # 获取训练标签以前的数据\n    map__last_records__user_row = dict(zip(last_records['user_id'],last_records['row_id']))\n    \n    train_questions_info['filter_row'] = train_questions_info['user_id'].map(map__last_records__user_row)\n    train_lectures_info['filter_row'] = train_lectures_info['user_id'].map(map__last_records__user_row)\n\n    train_questions_info = train_questions_info[train_questions_info['row_id']<train_questions_info['filter_row']]\n    train_lectures_info = train_lectures_info[train_lectures_info['row_id']<train_lectures_info['filter_row']]\n    \n    # 获取特征\n    train_lectures_info__user_f = get_lecture_basic_features__user(train_lectures_info)\n    # train_lectures_info__user_tag_f = get_lecture_basic_features__user_tag(train_lectures_info)\n    train_questions_info__user_f = get_questions_basic_features__user(train_questions_info)\n    # train_questions_info__user_part_f = get_questions_basic_features__user_part(train_questions_info)\n    train_questions_info__user_content_f = get_questions_basic_features__content(train_questions_info)\n\n    last_records = last_records.merge(train_lectures_info__user_f,on=['user_id'],how='left')\n    last_records = last_records.merge(train_questions_info__user_f,on=['user_id'],how='left')\n    last_records = last_records.merge(train_questions_info__user_content_f,on=['content_id'],how='left')\n    \n    # 特征加入训练集\n    train_data = train_data.append(last_records)\n    print(len(train_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 修改\nremove_columns = ['user_id','row_id','content_type_id','user_answer','answered_correctly','filter_row']\nfeatures_columns = [c for c in train_data.columns if c not in remove_columns]\n\nX_test, y_test = valid_data[features_columns].values, valid_data['answered_correctly'].values\n\nX_train, y_train = train_data[features_columns].values, train_data['answered_correctly'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'metric': 'auc',\n    'num_leaves': 9,\n    'learning_rate': 0.3,\n    'feature_fraction_seed': 2,\n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 5,\n    'min_data': 20,\n    'min_hessian': 1,\n    'verbose': -1,\n    'silent': 0\n    }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_train = lgb.Dataset(X_train, y_train)\nlgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm = lgb.train(\n            params,\n            lgb_train,\n            num_boost_round=10000,\n            valid_sets=lgb_eval,\n            early_stopping_rounds=20\n            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iter_test = env.iter_test()\n\nfor (test_df, sample_prediction_df) in iter_test:\n    test_questions = test_df[test_df['content_type_id']==0]\n    test_questions_info = pd.merge(\n            left=test_questions,\n            right=questions,\n            how='left',\n            left_on='content_id',\n            right_on='question_id'\n            )\n    test_questions_info['prior_question_had_explanation'] = test_questions_info['prior_question_had_explanation'].map({'True':1,'False':0}).fillna(-1).astype(np.int8)\n    test_questions_info = test_questions_info.merge(test_lectures_info__user_f,on=['user_id'],how='left')\n    test_questions_info = test_questions_info.merge(test_questions_info__user_f,on=['user_id'],how='left')\n    test_questions_info = test_questions_info.merge(test_questions_info__user_content_f,on=['content_id'],how='left')\n        \n    # 修改\n    #remove_columns = ['user_id','row_id','content_type_id','user_answer','answered_correctly','filter_row']\n    #features_columns = [c for c in train_data.columns if c not in remove_columns]\n\n\n    X_test = test_questions_info[features_columns].values\n    \n    test_questions_info['answered_correctly'] =  gbm.predict(X_test)\n    \n    env.predict(test_questions_info.loc[test_questions_info['content_type_id'] == 0, ['row_id', 'answered_correctly']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}