{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/riiid-test-answer-prediction/example_sample_submission.csv\n",
      "/kaggle/input/riiid-test-answer-prediction/train.csv\n",
      "/kaggle/input/riiid-test-answer-prediction/example_test.csv\n",
      "/kaggle/input/riiid-test-answer-prediction/questions.csv\n",
      "/kaggle/input/riiid-test-answer-prediction/lectures.csv\n",
      "/kaggle/input/riiid-test-answer-prediction/riiideducation/__init__.py\n",
      "/kaggle/input/riiid-test-answer-prediction/riiideducation/competition.cpython-37m-x86_64-linux-gnu.so\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据集包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import riiideducation\n",
    "# env = riiideducation.make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# env = riiideducation.make_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '/kaggle/input/riiid-test-answer-prediction/'\n",
    "file_train = 'train.csv'\n",
    "file_questions = 'questions.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置读取行数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows =  100 * 10000\n",
    "# nrows = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取train训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\n",
    "                    dir_path + file_train, \n",
    "                    nrows=nrows, \n",
    "                    usecols=['row_id', 'timestamp', 'user_id', 'content_id', \n",
    "                             'content_type_id', 'task_container_id', 'answered_correctly',\n",
    "                            'prior_question_elapsed_time','prior_question_had_explanation'],\n",
    "                    dtype={\n",
    "                            'row_id': 'int64',\n",
    "                            'timestamp': 'int64',\n",
    "                            'user_id': 'int32',\n",
    "                            'content_id': 'int16',\n",
    "                            'content_type_id': 'int8',\n",
    "                            'task_container_id': 'int8',\n",
    "                            'answered_correctly': 'int8',\n",
    "                            'prior_question_elapsed_time': 'float32',\n",
    "                            'prior_question_had_explanation': 'str'\n",
    "                        }\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取问题数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = pd.read_csv(\n",
    "                        dir_path + file_questions, \n",
    "                        nrows=nrows,\n",
    "                        usecols=['question_id','bundle_id','part'], \n",
    "                        dtype={\n",
    "                           'question_id': 'int16',\n",
    "                           'bundle_id': 'int16',\n",
    "                           'part': 'int8',\n",
    "                       }\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理prior_question_had_explanation特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>5692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>56943</td>\n",
       "      <td>115</td>\n",
       "      <td>5716</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>118363</td>\n",
       "      <td>115</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>131167</td>\n",
       "      <td>115</td>\n",
       "      <td>7860</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>137965</td>\n",
       "      <td>115</td>\n",
       "      <td>7922</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  timestamp  user_id  content_id  content_type_id  task_container_id  \\\n",
       "0       0          0      115        5692                0                  1   \n",
       "1       1      56943      115        5716                0                  2   \n",
       "2       2     118363      115         128                0                  0   \n",
       "3       3     131167      115        7860                0                  3   \n",
       "4       4     137965      115        7922                0                  4   \n",
       "\n",
       "   answered_correctly  prior_question_elapsed_time  \\\n",
       "0                   1                          NaN   \n",
       "1                   1                      37000.0   \n",
       "2                   1                      55000.0   \n",
       "3                   1                      19000.0   \n",
       "4                   1                      11000.0   \n",
       "\n",
       "  prior_question_had_explanation  \n",
       "0                            NaN  \n",
       "1                          False  \n",
       "2                          False  \n",
       "3                          False  \n",
       "4                          False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                          Non-Null Count    Dtype  \n",
      "---  ------                          --------------    -----  \n",
      " 0   row_id                          1000000 non-null  int64  \n",
      " 1   timestamp                       1000000 non-null  int64  \n",
      " 2   user_id                         1000000 non-null  int32  \n",
      " 3   content_id                      1000000 non-null  int16  \n",
      " 4   content_type_id                 1000000 non-null  int8   \n",
      " 5   task_container_id               1000000 non-null  int8   \n",
      " 6   answered_correctly              1000000 non-null  int8   \n",
      " 7   prior_question_elapsed_time     976277 non-null   float32\n",
      " 8   prior_question_had_explanation  996184 non-null   object \n",
      "dtypes: float32(1), int16(1), int32(1), int64(2), int8(3), object(1)\n",
      "memory usage: 35.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['prior_question_had_explanation'] = train['prior_question_had_explanation'].map({'True':1,'False':0}).fillna(-1).astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 筛选数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['content_type_id']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据回收"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del a;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "857"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 压缩数据，取最后几行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num = 100\n",
    "train = train.groupby(['user_id']).tail(max_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 合并数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(\n",
    "        left=train,\n",
    "        right=questions,\n",
    "        how='left',\n",
    "        left_on='content_id',\n",
    "        right_on='question_id'\n",
    "        )\n",
    "# left join, right join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "      <th>question_id</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>part</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>5692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>5692</td>\n",
       "      <td>5692</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>56943</td>\n",
       "      <td>115</td>\n",
       "      <td>5716</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5716</td>\n",
       "      <td>5716</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>118363</td>\n",
       "      <td>115</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>131167</td>\n",
       "      <td>115</td>\n",
       "      <td>7860</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7860</td>\n",
       "      <td>7860</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>137965</td>\n",
       "      <td>115</td>\n",
       "      <td>7922</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7922</td>\n",
       "      <td>7922</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  timestamp  user_id  content_id  content_type_id  task_container_id  \\\n",
       "0       0          0      115        5692                0                  1   \n",
       "1       1      56943      115        5716                0                  2   \n",
       "2       2     118363      115         128                0                  0   \n",
       "3       3     131167      115        7860                0                  3   \n",
       "4       4     137965      115        7922                0                  4   \n",
       "\n",
       "   answered_correctly  prior_question_elapsed_time  \\\n",
       "0                   1                          NaN   \n",
       "1                   1                      37000.0   \n",
       "2                   1                      55000.0   \n",
       "3                   1                      19000.0   \n",
       "4                   1                      11000.0   \n",
       "\n",
       "   prior_question_had_explanation  question_id  bundle_id  part  \n",
       "0                              -1         5692       5692     5  \n",
       "1                               0         5716       5716     5  \n",
       "2                               0          128        128     1  \n",
       "3                               0         7860       7860     1  \n",
       "4                               0         7922       7922     1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 空缺数据填充0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 类别特征处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 【男，nv,nan,nv,nv】--> [1,0,1,0,0]\n",
    "# {'男'：1，'nv'：0}\n",
    "# 2 : max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cat_deal:\n",
    "    def __init__(self):\n",
    "        self.max_len = 0\n",
    "        self.dict_map = {}\n",
    "    \n",
    "    def fit(self, cat_list):\n",
    "        index = 1 \n",
    "        for cat_i in cat_list:\n",
    "            if cat_i not in self.dict_map:\n",
    "                self.dict_map[cat_i] = index\n",
    "                index += 1\n",
    "        self.max_len = index + 1\n",
    "        \n",
    "    def transform(self, cat_list):\n",
    "        cat_transform_list = []\n",
    "        for cat_i in cat_list:\n",
    "            if cat_i in self.dict_map:\n",
    "                cat_transform_list.append(self.dict_map[cat_i])\n",
    "            else:\n",
    "                cat_transform_list.append(0)\n",
    "        return cat_transform_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 浮点特征处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class float_deal:\n",
    "    def __init__(self):\n",
    "        self.max = 0\n",
    "        self.min = 0\n",
    "        self.max_min = 0 \n",
    "        \n",
    "    def fit(self, float_list):\n",
    "        for float_i in float_list:\n",
    "            if float_i < self.min:\n",
    "                self.min = float_i\n",
    "            if float_i > self.max:\n",
    "                self.max = float_i\n",
    "        self.max_min = self.max - self.min\n",
    "        \n",
    "    def transform(self, float_list):\n",
    "        float_transform_list = []\n",
    "        for float_i in float_list:\n",
    "            if float_i < self.min:\n",
    "                float_transform_list.append(0)\n",
    "            elif float_i > self.max:\n",
    "                float_transform_list.append(1)\n",
    "            else:\n",
    "                float_transform_list.append(float_i/self.max_min)\n",
    "        return float_transform_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对类别特征数据进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "content_id\n",
      "task_container_id\n",
      "prior_question_had_explanation\n",
      "bundle_id\n",
      "part\n"
     ]
    }
   ],
   "source": [
    "dict_cat_class = {}\n",
    "for columns in ['user_id','content_id',\\\n",
    "                'task_container_id','prior_question_had_explanation',\\\n",
    "                'bundle_id','part']:\n",
    "    dict_cat_class[columns] = cat_deal()\n",
    "    dict_cat_class[columns].fit(train[columns])\n",
    "\n",
    "    train[columns] = dict_cat_class[columns].transform(train[columns])\n",
    "    print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': <__main__.cat_deal at 0x7f23c6bf3810>,\n",
       " 'content_id': <__main__.cat_deal at 0x7f23c816f090>,\n",
       " 'task_container_id': <__main__.cat_deal at 0x7f23c5f5f290>,\n",
       " 'prior_question_had_explanation': <__main__.cat_deal at 0x7f23c6d61190>,\n",
       " 'bundle_id': <__main__.cat_deal at 0x7f23cb16ba10>,\n",
       " 'part': <__main__.cat_deal at 0x7f23c6a93fd0>}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_cat_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: 1, 1: 2, 2: 3, 3: 4, 4: 5, 6: 6, 7: 7}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_cat_class['part'].dict_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_cat_class['part'].max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 浮点特征处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp\n",
      "prior_question_elapsed_time\n"
     ]
    }
   ],
   "source": [
    "dict_float_class = {}\n",
    "for columns in ['timestamp','prior_question_elapsed_time']:\n",
    "    dict_float_class[columns] = float_deal()\n",
    "    dict_float_class[columns].fit(train[columns])\n",
    "    \n",
    "    train[columns] = dict_float_class[columns].transform(train[columns])\n",
    "    print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.max = 0\n",
    "# self.min = 0\n",
    "# self.max_min = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300000.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_float_class['prior_question_elapsed_time'].max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_float_class['prior_question_elapsed_time'].min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300000.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_float_class['prior_question_elapsed_time'].max_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化前：80000\n",
    "# 归一化后：80000 / (300000 - 0) = 0.26666666666666666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f23c5286b10>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['prior_question_elapsed_time'].hist(bins=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['prior_question_elapsed_time_0'] = train['prior_question_elapsed_time'].map(lambda x: 1 if x==0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras函数Lambda函数包装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze(embedding):\n",
    "    embedding = tf.squeeze(embedding,axis=1)\n",
    "    return embedding\n",
    "def concat(embedding_list):\n",
    "    embedding = tf.concat(embedding_list, axis=1)\n",
    "    return embedding\n",
    "def multiply(multi_x_y):\n",
    "    multi_x = multi_x_y[0]\n",
    "    multi_y = multi_x_y[1]\n",
    "    multi_x_y = tf.multiply(multi_x, multi_y)\n",
    "    return multi_x_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 浮点数据输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_timestamp = tf.keras.Input(shape=(1,))\n",
    "input_prior_question_elapsed_time = tf.keras.Input(shape=(1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 类别数据输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_user = tf.keras.Input(shape=(1,))\n",
    "input_content = tf.keras.Input(shape=(1,))\n",
    "input_task_container = tf.keras.Input(shape=(1,))\n",
    "input_prior_question_had_explanation = tf.keras.Input(shape=(1,))\n",
    "input_bundle = tf.keras.Input(shape=(1,))\n",
    "input_part = tf.keras.Input(shape=(1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 所有输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [input_timestamp,input_prior_question_elapsed_time,\\\n",
    "         input_user,input_content,\\\n",
    "         input_task_container,input_prior_question_had_explanation,\\\n",
    "         input_bundle,input_part]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 类别特征embeeding转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.layers.Embedding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_user = tf.keras.layers.Embedding(dict_cat_class['user_id'].max_len,\n",
    "                                           1, input_length=1)(input_user)\n",
    "embedding_user = tf.keras.layers.Lambda(squeeze)(embedding_user)\n",
    "\n",
    "embedding_content = tf.keras.layers.Embedding(dict_cat_class['content_id'].max_len,\n",
    "                                              1, input_length=1)(input_content)\n",
    "embedding_content = tf.keras.layers.Lambda(squeeze)(embedding_content)\n",
    "\n",
    "embedding_task_container = tf.keras.layers.Embedding(dict_cat_class['task_container_id'].max_len,\n",
    "                                                     1, input_length=1)(input_task_container)\n",
    "embedding_task_container = tf.keras.layers.Lambda(squeeze)(embedding_task_container)\n",
    "\n",
    "embedding_prior_question_had_explanation = tf.keras.layers.Embedding(dict_cat_class['prior_question_had_explanation'].max_len, \n",
    "                                                                     1, input_length=1)(input_prior_question_had_explanation)\n",
    "embedding_prior_question_had_explanation = tf.keras.layers.Lambda(squeeze)(embedding_prior_question_had_explanation)\n",
    "\n",
    "embedding_bundle = tf.keras.layers.Embedding(dict_cat_class['bundle_id'].max_len,\n",
    "                                             1, input_length=1)(input_bundle)\n",
    "embedding_bundle = tf.keras.layers.Lambda(squeeze)(embedding_bundle)\n",
    "\n",
    "embedding_part = tf.keras.layers.Embedding(dict_cat_class['part'].max_len,\n",
    "                                           1, input_length=1)(input_part)\n",
    "embedding_part = tf.keras.layers.Lambda(squeeze)(embedding_part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 合并类别特征对应的embeeding特征和浮点特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_all = [input_timestamp,input_prior_question_elapsed_time,\\\n",
    "                embedding_user, embedding_content, embedding_task_container,\\\n",
    "                embedding_prior_question_had_explanation, embedding_bundle, embedding_part]\n",
    "\n",
    "lr_all = embedding_all + [input_timestamp,input_prior_question_elapsed_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'input_1:0' shape=(None, 1) dtype=float32>,\n",
       " <tf.Tensor 'input_2:0' shape=(None, 1) dtype=float32>,\n",
       " <tf.Tensor 'lambda/Squeeze:0' shape=(None, 1) dtype=float32>,\n",
       " <tf.Tensor 'lambda_1/Squeeze:0' shape=(None, 1) dtype=float32>,\n",
       " <tf.Tensor 'lambda_2/Squeeze:0' shape=(None, 1) dtype=float32>,\n",
       " <tf.Tensor 'lambda_3/Squeeze:0' shape=(None, 1) dtype=float32>,\n",
       " <tf.Tensor 'lambda_4/Squeeze:0' shape=(None, 1) dtype=float32>,\n",
       " <tf.Tensor 'lambda_5/Squeeze:0' shape=(None, 1) dtype=float32>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logits regression线性层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lambda_6/concat:0' shape=(None, 10) dtype=float32>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_layer = tf.keras.layers.Lambda(concat)(lr_all) \n",
    "# lr_layer = tf.keras.layers.Dense(1, activation=tf.nn.relu/tf.nn.tanh)(lr_layer) \n",
    "logit = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(lr_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = sigmoid(wx)\n",
    "# x * sigmoid(x) 激活：rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型输入和输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Model(inputs=inputs, outputs=logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 编译模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ylogy + (1-y)log(1-y)\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['binary_crossentropy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置学习率自动0.1减少函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "plateau = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                            verbose=0,\n",
    "                            mode='min',\n",
    "                            factor=0.1,\n",
    "                            patience=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置早停函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                               verbose=0,\n",
    "                               mode='min',\n",
    "                               patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置保存点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'fold.h5',\n",
    "                             monitor='val_loss',\n",
    "                             verbose=0,\n",
    "                             mode='min',\n",
    "                             save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'summarymary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-7266cb7e8d84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarymary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'summarymary'"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 验证数据获取、剩下的数据为训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3824\n",
      "7646\n",
      "11466\n",
      "15285\n",
      "19104\n",
      "22923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "valid = pd.DataFrame()\n",
    "for i in range(6):\n",
    "    \n",
    "    # 获取验证标签数据\n",
    "    last_records = train.drop_duplicates('user_id', keep='last')\n",
    "    \n",
    "    # 获取验证标签以前的数据\n",
    "    map__last_records__user_row = dict(zip(last_records['user_id'],last_records['row_id']))\n",
    "    train['filter_row'] = train['user_id'].map(map__last_records__user_row)\n",
    "    train = train[train['row_id']<train['filter_row']]\n",
    "\n",
    "    # 特征加入验证集\n",
    "    valid = valid.append(last_records)\n",
    "    print(len(valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据特征切分以及删除train、valid，减少内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['timestamp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_columns = ['timestamp','prior_question_elapsed_time',\\\n",
    "                    'user_id','content_id',\\\n",
    "                    'task_container_id','prior_question_had_explanation',\\\n",
    "                    'bundle_id','part']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练和测试集数据切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, y_valid = [valid[columns].values for columns in features_columns], valid['answered_correctly'].values\n",
    "# del valid\n",
    "\n",
    "X_train, y_train = [train[columns].values for columns in features_columns], train['answered_correctly'].values\n",
    "# del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191436,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22923,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.7024 - binary_crossentropy: 0.7024 - val_loss: 0.6982 - val_binary_crossentropy: 0.6982\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7019 - binary_crossentropy: 0.7019 - val_loss: 0.6979 - val_binary_crossentropy: 0.6979\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7014 - binary_crossentropy: 0.7014 - val_loss: 0.6976 - val_binary_crossentropy: 0.6976\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7010 - binary_crossentropy: 0.7010 - val_loss: 0.6973 - val_binary_crossentropy: 0.6973\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7005 - binary_crossentropy: 0.7005 - val_loss: 0.6970 - val_binary_crossentropy: 0.6970\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7000 - binary_crossentropy: 0.7000 - val_loss: 0.6967 - val_binary_crossentropy: 0.6967\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6996 - binary_crossentropy: 0.6996 - val_loss: 0.6964 - val_binary_crossentropy: 0.6964\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6991 - binary_crossentropy: 0.6991 - val_loss: 0.6961 - val_binary_crossentropy: 0.6961\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6986 - binary_crossentropy: 0.6986 - val_loss: 0.6958 - val_binary_crossentropy: 0.6958\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6981 - binary_crossentropy: 0.6981 - val_loss: 0.6955 - val_binary_crossentropy: 0.6955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f238e872250>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          epochs=10,\n",
    "          batch_size=512 * 500 * 2,\n",
    "          verbose=1,\n",
    "          shuffle=True,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=[plateau, early_stopping, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试集验证结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5132494126811524\n"
     ]
    }
   ],
   "source": [
    "y_valid_proba = model.predict(X_valid, verbose=0, batch_size=512)\n",
    "auc = roc_auc_score(y_valid, y_valid_proba)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 继续训练和验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6977 - binary_crossentropy: 0.6977 - val_loss: 0.6952 - val_binary_crossentropy: 0.6952\n",
      "0.5168912015196118\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          epochs=1,\n",
    "          batch_size=512 * 500 * 2,\n",
    "          verbose=1,\n",
    "          shuffle=True,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=[plateau, early_stopping, checkpoint])\n",
    "\n",
    "y_valid_proba = model.predict(X_valid, verbose=0, batch_size=512)\n",
    "auc = roc_auc_score(y_valid, y_valid_proba)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试集环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "content_id\n",
      "task_container_id\n",
      "prior_question_had_explanation\n",
      "bundle_id\n",
      "part\n",
      "timestamp\n",
      "prior_question_elapsed_time\n",
      "user_id\n",
      "content_id\n",
      "task_container_id\n",
      "prior_question_had_explanation\n",
      "bundle_id\n",
      "part\n",
      "timestamp\n",
      "prior_question_elapsed_time\n",
      "user_id\n",
      "content_id\n",
      "task_container_id\n",
      "prior_question_had_explanation\n",
      "bundle_id\n",
      "part\n",
      "timestamp\n",
      "prior_question_elapsed_time\n",
      "user_id\n",
      "content_id\n",
      "task_container_id\n",
      "prior_question_had_explanation\n",
      "bundle_id\n",
      "part\n",
      "timestamp\n",
      "prior_question_elapsed_time\n"
     ]
    }
   ],
   "source": [
    "# for (test_df, sample_prediction_df) in iter_test:\n",
    "\n",
    "#     # 处理特征\n",
    "#     test_df['prior_question_had_explanation'] = test_df['prior_question_had_explanation'].map({'True':1,'False':0}).fillna(-1).astype(np.int8)\n",
    "\n",
    "#     # 合并样本\n",
    "#     test_df = pd.merge(\n",
    "#         left=test_df,\n",
    "#         right=questions,\n",
    "#         how='left',\n",
    "#         left_on='content_id',\n",
    "#         right_on='question_id'\n",
    "#         )\n",
    "\n",
    "#     test_df = test_df.fillna(0)\n",
    "\n",
    "\n",
    "#     for columns in ['user_id','content_id',\\\n",
    "#                     'task_container_id','prior_question_had_explanation',\\\n",
    "#                     'bundle_id','part']:\n",
    "\n",
    "#         test_df[columns] = dict_cat_class[columns].transform(test_df[columns])\n",
    "#         print(columns)\n",
    "\n",
    "\n",
    "#     for columns in ['timestamp','prior_question_elapsed_time']:\n",
    "      \n",
    "#         test_df[columns] = dict_float_class[columns].transform(test_df[columns])\n",
    "#         print(columns)\n",
    "\n",
    "#     X_test = [test_df[columns].values for columns in features_columns]\n",
    "\n",
    "#     test_df['answered_correctly'] =  model.predict(X_test, verbose=0, batch_size=512)\n",
    "#     env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
